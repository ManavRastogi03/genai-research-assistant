# ğŸ§  genai-research-assistant

An AI-powered assistant that intelligently summarizes, queries, and quizzes research documents (PDF/TXT) with contextual understanding using Gemini AI and LangChain.

---

## ğŸš€ Overview

The `genai-research-assistant` enables users to:

- ğŸ“„ Upload structured research or technical documents
- ğŸ§  Receive an automatic summary (â‰¤150 words)
- ğŸ’¬ Ask comprehension-based questions
- ğŸ¯ Be challenged with logic-based questions
- ğŸ“Œ Get grounded answers with in-document references

Designed with clean UX, minimal hallucination, and robust reasoning.

---

## ğŸ›  Features

- ğŸ“„ **Document Upload** â€“ Accepts PDF or TXT files (â‰¤10MB)
- ğŸ§  **Auto Summarization** â€“ LLM-powered summary on upload
- ğŸ’¬ **Ask Anything** â€“ Free-form contextual Q&A grounded in the text
- ğŸ¯ **Challenge Me** â€“ Logic/inference-based MCQs with evaluation
- ğŸ“Œ **Answer Justification** â€“ Cites exact section/snippet from the document
- ğŸ” **Memory Handling** *(Bonus)* â€“ Follow-up question awareness
- âœ¨ **Answer Highlighting** *(Bonus)* â€“ Visual snippet display

---

## ğŸ§± System Design

```mermaid
graph TD
A[ğŸ“„ User Uploads Document] --> B[ğŸ“‘ Document Processor]
B --> C[ğŸ§¹ Cleaner + Text Chunker]
C --> D[ğŸ“Š FAISS Vector Index]
C --> E[ğŸ§  LLM Summary Generator]
D --> F{Interaction Mode}
F -->|ğŸ’¬ Ask Anything| G[LLM + Context Retriever â†’ Answer + Reference]
F -->|ğŸ¯ Challenge Me| H[Question Generator â†’ User Answer â†’ Evaluator]
Embeddings are created from text chunks

Chunks are queried for relevance via semantic search

Only top-k chunks are passed to the LLM to minimize hallucination

ğŸ“¦ Tech Stack
Layer	Technology
UI	Streamlit
Backend	FastAPI
LLM	Gemini API / GPT-4
Chunking	LangChain
Vector Search	FAISS or ChromaDB
PDF Parsing	PyMuPDF
Evaluation	LLM-based scoring

ğŸ§ª Getting Started
1ï¸âƒ£ Clone the Repository
bash
Copy
Edit
git clone https://github.com/ManavRastogi03/genai-research-assistant.git
cd genai-research-assistant
2ï¸âƒ£ Create & Activate Virtual Environment
bash
Copy
Edit
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
3ï¸âƒ£ Install Dependencies
bash
Copy
Edit
pip install -r requirements.txt
4ï¸âƒ£ Add API Key
Create a .env file in the root directory:

env
Copy
Edit
GEMINI_API_KEY=your_gemini_api_key_here
5ï¸âƒ£ Run the App
bash
Copy
Edit
# Start backend
cd backend
uvicorn main:app --reload

# Start frontend
cd ../fronted
streamlit run app.py
Then open: http://localhost:8501

ğŸ“ Folder Layout
arduino
Copy
Edit
genai-research-assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”œâ”€â”€ llm_service.py
â”‚   â”œâ”€â”€ api_models.py
â”‚   â””â”€â”€ embeddings.py
â”‚
â”œâ”€â”€ fronted/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ text_utils.py
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ uploads/
â”‚
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ“ Example Use Case
Upload a PDF research paper.

Read the summary instantly.

Ask: "What were the key findings in section 2?"

Receive a grounded answer with citation like:
â€œAs per paragraph 2 of Section 2...â€

Use "Challenge Me" mode to test your comprehension.

âœ… Evaluation Checklist
Criteria	Weight
ğŸ“– Response Accuracy & Justification	30%
ğŸ§  Challenge Me Evaluation Logic	20%
ğŸ¨ UI/UX Flow & Simplicity	15%
ğŸ§¹ Code Quality & Documentation	15%
ğŸŒŸ Creative / Bonus Features	10%
ğŸš« Low Hallucination & Context Use	10%

ğŸ“œ License
MIT Â© ManavRastogi03